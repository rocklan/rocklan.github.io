---
date: 2006-07-12
category: technical
readtime: true
---
A couple of weeks ago I discovered <a href="http://waiterrant.net/">Waiter Rant</a>, an amusing blog written by a waiter who works in an expensive Italian restaurant. It's a great great, and the guy has done over 300 posts! So, do I want to sit there and download them all? Not really.<br /><br />Plus the worst part of it is that his pages are huge:<br /><pre>	Documents (1 file)	23 kb<br />	Images (36 files)	58 kb<br />	Style Sheets (1 file)	9 kb<br />	Scripts (3 files)	5 kb<br />	Total	            94 kb<br /></pre>    <br />94 kb for 1 post! That means to download his >330 post website it would take over 29 meg! That's just freaking stupid. Do I really want to download his ads every time I want to read a story about a bitchy customer? Nope. So instead I wrote a program to download just the neccesary parts for me and compile it all together. <br /><br />Each post now comes in at a handsome 10k. Now his entirety of posts comes to 3 megs, and I can read it offline. Cool. The code is c#.net, and to compile it you can use:<br /><br />\WINDOWS\Microsoft.NET\Framework\v1.1.4322\csc req.cs<br /><br />and then you can run the executable. <br /><pre><br />using System;<br />using System.Net;<br />using System.IO;<br />using System.Text.RegularExpressions;<br /><br />public class req<br />{<br />    static WebProxy proxy;<br />    <br />    public static String getHtml(int number) <br />    {<br />        WebRequest req = WebRequest.Create("http://waiterrant.net/?p=" + number);<br />        req.Proxy = proxy;<br />        WebResponse resp = req.GetResponse();<br />        Stream strm = resp.GetResponseStream();<br />        StreamReader sr = new StreamReader(strm);<br />        string line = "";<br />        string output = "";<br />        while (line != null)<br />        {<br />            output = output + line;<br />            line = sr.ReadLine();<br />            Match m = Regex.Match(line, "Subscribe to comments with");<br />            if (m.Success)<br />            {<br />                line = null;<br />            }<br />        }<br />        strm.Close();<br />        return output;<br />    } <br />    <br />    static void Main()<br />    {<br />        proxy = new WebProxy("http://myproxy:80/",true);<br />        proxy.Credentials = new NetworkCredential("proxyusername","proxypassword", "proxydomain");<br /><br />        int i;<br />        int startpost = 1;<br />        int endpost = 10;<br />        System.IO.StreamWriter writer;<br />        writer = System.IO.File.CreateText("c:\\temp\\waiter2.htm");<br />        for (i=endpost;i>startpost;i--)<br />        {<br />            String html = getHtml(i);<br />            Match m = Regex.Match(html, "&lt;div class=\"archivepost\"&gt;(.*)from your own site");<br />            if (m.Success)<br />            {<br />                writer.WriteLine ("&lt;table&gt;&lt;tr&gt;&lt;td&gt;" + m + "&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;");<br />                writer.WriteLine (html);<br />                Console.WriteLine ("Downloaded post: " + i);<br />            }<br />        }<br />        writer.Close();<br />    }<br />}</pre> <br />PS <a href="http://www.metaltheater.com/article.asp?id=62">Paris the Homemaker</a> is still up.